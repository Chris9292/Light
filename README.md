# Light2
![Logo](https://github.com/Chris9292/Light/blob/main/Logo/LIGHT2.png)

## Description

### Abstract
In the near future, the vision and the need of establishing an active human presence on the
moon seems all the more urgent but more importantly all the more feasible after certain
technological advancements are made. To begin with, the completion of space related tasks
is a cognitively demanding and highly complex process that requires a high level of training.
Furthermore, the orientation and localization of an astronaut in real or analogue missions
requires constant communication with the base station’s operators. It is, therefore, necessary
to overcome these limitations in order to reduce human error and increase the situational
awareness of the astronaut.

In view of the vital role that new technologies will play in space development, LIGHT2 (Lunar
navIGation HelmeT) aims at designing, implementing and testing an AR-based mission
assistance system for use in future planetary mission analogues or even real missions. The
system will consist of a mixed reality headset (Microsoft HoloLens), on which the information
vital to the mission will be projected, accompanied by a weather station with appropriate
sensors and a camera - which will serve as an environment sensing device, and a base station
serving as operational support.

Biometric data characterizing the astronaut’s medical status, data concerning the
environmental conditions as well as a map of the area will be available. Moreover, an
interactable graphical interface will provide the astronaut with the necessary functions to
complete his missions. Lastly, a networking system will relay the data from the weather box to
the helmet.

For the IGLUNA 2021 Virtual Field Campaign, a lunar-like environment will be set up on an
abandoned mining area, where an analogue EVA moonwalk will be recorded, showcasing the
AR system’s full capabilities. During the duration of the shooting, a lunar weather station will
be placed nearby, which will be collecting temperature, radiation, and humidity measurements,
as well as visual feed, and sending them through the control room to the Hololens in real-time.

In the long-term, LIGHT’s system, by properly adjusting its features, incorporating networking
capabilities with other devices (IoT, Robots, specialized equipment) and implementing AI
guidance, could provide a more general and structured approach to team coordination and
problem solving in the Industry or the Medical field.


### Project Statement
LIGHT2 will be a general tool for astronauts’ navigation and assistance on both real and
analogue lunar exploration missions based on Augmented Reality technology.

### Need Statement
Taking into consideration the complexity of a lunar mission, the cognitive load necessary for
the orientation or localization of the astronaut and the successful completion of diverse mission
objectives such as the repair of machinery and retrieval of items adds to the already heavy
training regimes of astronauts. Consequently, the available time for free exploration and
scientific field work in real missions is heavily reduced. Space agencies ought to streamline
the process, should they eventually establish a sustainable infrastructure and economy on the
Moon and beyond.

### Project Relevance
LIGHT2 is addressed primarily to space agencies and space-related companies for analogue
or real space missions. The ability of AR technologies to visually represent information and
provide interactability with said information could drastically simplify the training process of
astronauts for space-related activities. Coupled with external communication, the software
could aid even non-specialized personnel in completing complex tasks (equipment
repair/maintenance, navigation in unknown/hostile environments, etc), paving the way for the
commercialization of space. Moreover, both “structuring” the astronaut’s experience through
an easy-to-use interface and increasing their autonomy could aid in several scientific activities
on the surface of the moon, thus positively impacting future space research and operations.

These same principles of simplification of complex processes, remote coordination/aid, and
increase of autonomy, apply to diverse tasks in the Industry, Construction work, Healthcare,
Experimental Science and could very well establish the use of AR systems such as LIGHT2 in
the workflow of scientists, engineers, and technicians on Earth.

Finally, the integration of AR technologies and networks of sensors is an exciting research
area and business avenue, especially in the upcoming era of “smart” Homes and Cities. Thus,
a system which demonstrates the ability to remotely communicate and control devices through
AR interfaces would generate great academic and business interest.

## Demo

- [Final Presentation](https://www.youtube.com/watch?v=UNxE0y2D4qE)
- [Project Paper](https://github.com/Chris9292/Light/blob/main/ProjectDocuments/IGL_P08_LIGHT2_SD_05.pdf)


## Team Composition

### Project Management
- Thanasis Askitopoulos

### Software Development
- Thanasis Askitopoulos
- Dimitris Tolias
- Christos Kagkelidis
- Giorgos Papadopoulos

### Electronics Engineering
- Panagiota Boskou
- Giota Chita
- Konstantina Vasileiadou

### Exhibition Design, Graphics Design
- Katerina Kolovou
- Terkenli Lydia
- Athena Athanasiadou

### Video Director
- Nikos Chatzisavvidis

### Video Editor
- Sophia Chatzigianni

## Contact

 - [Facebook](https://www.facebook.com/beamauth)
 - [Instagram](https://www.instagram.com/beamauth/)
